# Credits

This is a remix from https://github.com/pytorch/tutorials

# Content

This is the first steps of the PyTorch tutorial.
The purpose is to get the audience to get the audience familiar with PyTorch.

## Lab 0: 0-what-is-pytorch

A brief introduction to the basics of PyTorch.

**NOTE** In the last part of this lab cuda is used. If you have a cuda enabled machine, read the README.md in the root of this repo on how to use nvidia-docker.

## Lab 1: 1-automatic-differentiation

An introduction to automatic differentiation in PyTorch.

## Lab 2: 2-neural-networks

An introduction to building a simple neural network with PyTorch.

## Lab 3: 3-cifar10

An introduction to data loading, image classification, and training with PyTorch.

# Prerequisites

Lab 0 and 1 require understanding of Linear Algebra.
If the recipient does not have this understanding, then checkout [Andrew Ng's linear algebra review](https://www.coursera.org/learn/machine-learning/lecture/38jIT/matrices-and-vectors).

Lab 2 requires fundamental understanding of regression, classification, and neural networks.
If the recipient does not have this understanding, then checkout week 1 through 6 in [Andrew Ng's machine learning course](https://www.coursera.org/learn/machine-learning).

Lab 3 requires understanding of convolutional neural networks.
If the recipient does not have this understanding, then checkout [Stanford's cs231 lecture 6](https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv).
